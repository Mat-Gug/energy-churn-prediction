{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn prediction for an energy company ðŸ”ŒðŸ’¡\n",
    "\n",
    "## Part 1 - Importing the data and performing data quality checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by quickly inspecting the two datasets stored in `client_data_raw.csv` and `price_data_raw.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>channel_sales</th>\n",
       "      <th>cons_12m</th>\n",
       "      <th>cons_gas_12m</th>\n",
       "      <th>cons_last_month</th>\n",
       "      <th>date_activ</th>\n",
       "      <th>date_end</th>\n",
       "      <th>date_modif_prod</th>\n",
       "      <th>date_renewal</th>\n",
       "      <th>forecast_cons_12m</th>\n",
       "      <th>...</th>\n",
       "      <th>has_gas</th>\n",
       "      <th>imp_cons</th>\n",
       "      <th>margin_gross_pow_ele</th>\n",
       "      <th>margin_net_pow_ele</th>\n",
       "      <th>nb_prod_act</th>\n",
       "      <th>net_margin</th>\n",
       "      <th>num_years_antig</th>\n",
       "      <th>origin_up</th>\n",
       "      <th>pow_max</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24011ae4ebbe3035111d65fa7c15bc57</td>\n",
       "      <td>foosdfpfkusacimwkcsosbicdxkicaua</td>\n",
       "      <td>0</td>\n",
       "      <td>54946</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-06-15</td>\n",
       "      <td>2016-06-15</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>2015-06-23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>t</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.44</td>\n",
       "      <td>25.44</td>\n",
       "      <td>2</td>\n",
       "      <td>678.99</td>\n",
       "      <td>3</td>\n",
       "      <td>lxidpiddsbxsbosboudacockeimpuepw</td>\n",
       "      <td>43.648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d29c2c54acc38ff3c0614d0a653813dd</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>4660</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2009-08-21</td>\n",
       "      <td>2016-08-30</td>\n",
       "      <td>2009-08-21</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>189.95</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.38</td>\n",
       "      <td>16.38</td>\n",
       "      <td>1</td>\n",
       "      <td>18.89</td>\n",
       "      <td>6</td>\n",
       "      <td>kamkkxfxxuwbdslkwifmmcsiusiuosws</td>\n",
       "      <td>13.800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>764c75f661154dac3a6c254cd082ea7d</td>\n",
       "      <td>foosdfpfkusacimwkcsosbicdxkicaua</td>\n",
       "      <td>544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-04-16</td>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>2010-04-16</td>\n",
       "      <td>2015-04-17</td>\n",
       "      <td>47.96</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.60</td>\n",
       "      <td>28.60</td>\n",
       "      <td>1</td>\n",
       "      <td>6.60</td>\n",
       "      <td>6</td>\n",
       "      <td>kamkkxfxxuwbdslkwifmmcsiusiuosws</td>\n",
       "      <td>13.856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bba03439a292a1e166f80264c16191cb</td>\n",
       "      <td>lmkebamcaaclubfxadlmueccxoimlema</td>\n",
       "      <td>1584</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-03-30</td>\n",
       "      <td>2016-03-30</td>\n",
       "      <td>2010-03-30</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>240.04</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.22</td>\n",
       "      <td>30.22</td>\n",
       "      <td>1</td>\n",
       "      <td>25.46</td>\n",
       "      <td>6</td>\n",
       "      <td>kamkkxfxxuwbdslkwifmmcsiusiuosws</td>\n",
       "      <td>13.200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149d57cf92fc41cf94415803a877cb4b</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>4425</td>\n",
       "      <td>0</td>\n",
       "      <td>526</td>\n",
       "      <td>2010-01-13</td>\n",
       "      <td>2016-03-07</td>\n",
       "      <td>2010-01-13</td>\n",
       "      <td>2015-03-09</td>\n",
       "      <td>445.75</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>52.32</td>\n",
       "      <td>44.91</td>\n",
       "      <td>44.91</td>\n",
       "      <td>1</td>\n",
       "      <td>47.98</td>\n",
       "      <td>6</td>\n",
       "      <td>kamkkxfxxuwbdslkwifmmcsiusiuosws</td>\n",
       "      <td>19.800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id                     channel_sales  \\\n",
       "0  24011ae4ebbe3035111d65fa7c15bc57  foosdfpfkusacimwkcsosbicdxkicaua   \n",
       "1  d29c2c54acc38ff3c0614d0a653813dd                           MISSING   \n",
       "2  764c75f661154dac3a6c254cd082ea7d  foosdfpfkusacimwkcsosbicdxkicaua   \n",
       "3  bba03439a292a1e166f80264c16191cb  lmkebamcaaclubfxadlmueccxoimlema   \n",
       "4  149d57cf92fc41cf94415803a877cb4b                           MISSING   \n",
       "\n",
       "   cons_12m  cons_gas_12m  cons_last_month  date_activ    date_end  \\\n",
       "0         0         54946                0  2013-06-15  2016-06-15   \n",
       "1      4660             0                0  2009-08-21  2016-08-30   \n",
       "2       544             0                0  2010-04-16  2016-04-16   \n",
       "3      1584             0                0  2010-03-30  2016-03-30   \n",
       "4      4425             0              526  2010-01-13  2016-03-07   \n",
       "\n",
       "  date_modif_prod date_renewal  forecast_cons_12m  ...  has_gas  imp_cons  \\\n",
       "0      2015-11-01   2015-06-23               0.00  ...        t      0.00   \n",
       "1      2009-08-21   2015-08-31             189.95  ...        f      0.00   \n",
       "2      2010-04-16   2015-04-17              47.96  ...        f      0.00   \n",
       "3      2010-03-30   2015-03-31             240.04  ...        f      0.00   \n",
       "4      2010-01-13   2015-03-09             445.75  ...        f     52.32   \n",
       "\n",
       "   margin_gross_pow_ele  margin_net_pow_ele  nb_prod_act  net_margin  \\\n",
       "0                 25.44               25.44            2      678.99   \n",
       "1                 16.38               16.38            1       18.89   \n",
       "2                 28.60               28.60            1        6.60   \n",
       "3                 30.22               30.22            1       25.46   \n",
       "4                 44.91               44.91            1       47.98   \n",
       "\n",
       "  num_years_antig                         origin_up  pow_max  churn  \n",
       "0               3  lxidpiddsbxsbosboudacockeimpuepw   43.648      1  \n",
       "1               6  kamkkxfxxuwbdslkwifmmcsiusiuosws   13.800      0  \n",
       "2               6  kamkkxfxxuwbdslkwifmmcsiusiuosws   13.856      0  \n",
       "3               6  kamkkxfxxuwbdslkwifmmcsiusiuosws   13.200      0  \n",
       "4               6  kamkkxfxxuwbdslkwifmmcsiusiuosws   19.800      0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "repo_path = \"/workspaces/myfolder/energy-churn-prediction\"\n",
    "\n",
    "raw_client_df = pd.read_csv(f\"{repo_path}/data/client_data_raw.csv\")\n",
    "raw_client_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_date</th>\n",
       "      <th>price_off_peak_var</th>\n",
       "      <th>price_peak_var</th>\n",
       "      <th>price_mid_peak_var</th>\n",
       "      <th>price_off_peak_fix</th>\n",
       "      <th>price_peak_fix</th>\n",
       "      <th>price_mid_peak_fix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>038af19179925da21a25619c5a24b745</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0.151367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.266931</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>038af19179925da21a25619c5a24b745</td>\n",
       "      <td>2015-02-01</td>\n",
       "      <td>0.151367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.266931</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>038af19179925da21a25619c5a24b745</td>\n",
       "      <td>2015-03-01</td>\n",
       "      <td>0.151367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.266931</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>038af19179925da21a25619c5a24b745</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>0.149626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.266931</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>038af19179925da21a25619c5a24b745</td>\n",
       "      <td>2015-05-01</td>\n",
       "      <td>0.149626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.266931</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192997</th>\n",
       "      <td>16f51cdc2baa19af0b940ee1b3dd17d5</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>0.119916</td>\n",
       "      <td>0.102232</td>\n",
       "      <td>0.076257</td>\n",
       "      <td>40.728885</td>\n",
       "      <td>24.43733</td>\n",
       "      <td>16.291555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192998</th>\n",
       "      <td>16f51cdc2baa19af0b940ee1b3dd17d5</td>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>0.119916</td>\n",
       "      <td>0.102232</td>\n",
       "      <td>0.076257</td>\n",
       "      <td>40.728885</td>\n",
       "      <td>24.43733</td>\n",
       "      <td>16.291555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192999</th>\n",
       "      <td>16f51cdc2baa19af0b940ee1b3dd17d5</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>0.119916</td>\n",
       "      <td>0.102232</td>\n",
       "      <td>0.076257</td>\n",
       "      <td>40.728885</td>\n",
       "      <td>24.43733</td>\n",
       "      <td>16.291555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193000</th>\n",
       "      <td>16f51cdc2baa19af0b940ee1b3dd17d5</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>0.119916</td>\n",
       "      <td>0.102232</td>\n",
       "      <td>0.076257</td>\n",
       "      <td>40.728885</td>\n",
       "      <td>24.43733</td>\n",
       "      <td>16.291555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193001</th>\n",
       "      <td>16f51cdc2baa19af0b940ee1b3dd17d5</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>0.119916</td>\n",
       "      <td>0.102232</td>\n",
       "      <td>0.076257</td>\n",
       "      <td>40.728885</td>\n",
       "      <td>24.43733</td>\n",
       "      <td>16.291555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193002 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  price_date  price_off_peak_var  \\\n",
       "0       038af19179925da21a25619c5a24b745  2015-01-01            0.151367   \n",
       "1       038af19179925da21a25619c5a24b745  2015-02-01            0.151367   \n",
       "2       038af19179925da21a25619c5a24b745  2015-03-01            0.151367   \n",
       "3       038af19179925da21a25619c5a24b745  2015-04-01            0.149626   \n",
       "4       038af19179925da21a25619c5a24b745  2015-05-01            0.149626   \n",
       "...                                  ...         ...                 ...   \n",
       "192997  16f51cdc2baa19af0b940ee1b3dd17d5  2015-08-01            0.119916   \n",
       "192998  16f51cdc2baa19af0b940ee1b3dd17d5  2015-09-01            0.119916   \n",
       "192999  16f51cdc2baa19af0b940ee1b3dd17d5  2015-10-01            0.119916   \n",
       "193000  16f51cdc2baa19af0b940ee1b3dd17d5  2015-11-01            0.119916   \n",
       "193001  16f51cdc2baa19af0b940ee1b3dd17d5  2015-12-01            0.119916   \n",
       "\n",
       "        price_peak_var  price_mid_peak_var  price_off_peak_fix  \\\n",
       "0             0.000000            0.000000           44.266931   \n",
       "1             0.000000            0.000000           44.266931   \n",
       "2             0.000000            0.000000           44.266931   \n",
       "3             0.000000            0.000000           44.266931   \n",
       "4             0.000000            0.000000           44.266931   \n",
       "...                ...                 ...                 ...   \n",
       "192997        0.102232            0.076257           40.728885   \n",
       "192998        0.102232            0.076257           40.728885   \n",
       "192999        0.102232            0.076257           40.728885   \n",
       "193000        0.102232            0.076257           40.728885   \n",
       "193001        0.102232            0.076257           40.728885   \n",
       "\n",
       "        price_peak_fix  price_mid_peak_fix  \n",
       "0              0.00000            0.000000  \n",
       "1              0.00000            0.000000  \n",
       "2              0.00000            0.000000  \n",
       "3              0.00000            0.000000  \n",
       "4              0.00000            0.000000  \n",
       "...                ...                 ...  \n",
       "192997        24.43733           16.291555  \n",
       "192998        24.43733           16.291555  \n",
       "192999        24.43733           16.291555  \n",
       "193000        24.43733           16.291555  \n",
       "193001        24.43733           16.291555  \n",
       "\n",
       "[193002 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_price_df = pd.read_csv(f\"{repo_path}/data/price_data_raw.csv\")\n",
    "raw_price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                 object\n",
      "channel_sales                      object\n",
      "cons_12m                            int64\n",
      "cons_gas_12m                        int64\n",
      "cons_last_month                     int64\n",
      "date_activ                         object\n",
      "date_end                           object\n",
      "date_modif_prod                    object\n",
      "date_renewal                       object\n",
      "forecast_cons_12m                 float64\n",
      "forecast_cons_year                  int64\n",
      "forecast_discount_energy          float64\n",
      "forecast_meter_rent_12m           float64\n",
      "forecast_price_energy_off_peak    float64\n",
      "forecast_price_energy_peak        float64\n",
      "forecast_price_pow_off_peak       float64\n",
      "has_gas                            object\n",
      "imp_cons                          float64\n",
      "margin_gross_pow_ele              float64\n",
      "margin_net_pow_ele                float64\n",
      "nb_prod_act                         int64\n",
      "net_margin                        float64\n",
      "num_years_antig                     int64\n",
      "origin_up                          object\n",
      "pow_max                           float64\n",
      "churn                               int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(raw_client_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                     object\n",
      "price_date             object\n",
      "price_off_peak_var    float64\n",
      "price_peak_var        float64\n",
      "price_mid_peak_var    float64\n",
      "price_off_peak_fix    float64\n",
      "price_peak_fix        float64\n",
      "price_mid_peak_fix    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(raw_price_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the previous two cells, Pandas did not correctly infer the date columns in both datasets. We'll use `pd.to_datetime()` to convert them to the proper `datetime` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'client_df':\n",
      "\n",
      "- Type of date_activ variable after conversion: datetime64[ns]\n",
      "- Type of date_end variable after conversion: datetime64[ns]\n",
      "- Type of date_modif_prod variable after conversion: datetime64[ns]\n",
      "- Type of date_renewal variable after conversion: datetime64[ns]\n",
      "--------------------------------\n",
      "\n",
      "'price_df':\n",
      "Type of price_date variable after conversion: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "client_df = raw_client_df.copy()\n",
    "price_df = raw_price_df.copy()\n",
    "\n",
    "client_date_cols = [col for col in client_df.columns if col.startswith('date')]\n",
    "price_date_col = 'price_date'\n",
    "\n",
    "print(\"'client_df':\")\n",
    "print()\n",
    "for col in client_date_cols:\n",
    "    client_df[col] = pd.to_datetime(client_df[col], format='%Y-%m-%d', errors='coerce')\n",
    "    print(f\"- Type of {col} variable after conversion: {client_df[col].dtypes}\")\n",
    "\n",
    "print(\"--------------------------------\")\n",
    "print()\n",
    "\n",
    "print(\"'price_df':\")\n",
    "price_df[price_date_col] = pd.to_datetime(price_df[price_date_col], format='%Y-%m-%d', errors='coerce')\n",
    "print(f\"Type of {price_date_col} variable after conversion: {price_df[price_date_col].dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `channel_sales` and `origin_up` variables in `raw_client_df` have been encoded into hashed text strings for privacy reasons. To improve readability, we will map these values to more intuitive category labels. Additionally, we'll convert `has_gas` and `churn` values to `'Yes'` and `'No'` for the same reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping dictionary for 'channel_sales':\n",
      " {'foosdfpfkusacimwkcsosbicdxkicaua': 'Channel 1', 'lmkebamcaaclubfxadlmueccxoimlema': 'Channel 2', 'usilxuppasemubllopkaafesmlibmsdf': 'Channel 3', 'ewpakwlliwisiwduibdlfmalxowmwpci': 'Channel 4', 'epumfxlbckeskwekxbiuasklxalciiuu': 'Channel 5', 'sddiedcslfslkckwlfkdpoeeailfpeds': 'Channel 6', 'fixdbufsefwooaasfcxdxadsiekoceaa': 'Channel 7', 'MISSING': 'Channel Missing'}\n",
      "---------------------------------------------\n",
      "Mapping dictionary for 'origin_up':\n",
      " {'lxidpiddsbxsbosboudacockeimpuepw': 'Campaign 1', 'kamkkxfxxuwbdslkwifmmcsiusiuosws': 'Campaign 2', 'ldkssxwpmemidmecebumciepifcamkci': 'Campaign 3', 'usapbepcfoloekilkwsdiboslwaxobdp': 'Campaign 4', 'ewxeelcelemmiwuafmddpobolfuxioce': 'Campaign 5', 'MISSING': 'Campaign Missing'}\n",
      "---------------------------------------------\n",
      "Mapping dictionary for 'churn':\n",
      " {0: 'No', 1: 'Yes'}\n",
      "---------------------------------------------\n",
      "Mapping dictionary for 'has_gas':\n",
      " {'f': 'No', 't': 'Yes'}\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "hashed_cols = ['channel_sales', 'origin_up']\n",
    "prefixes = ['Channel', 'Campaign']\n",
    "mapping_dicts = {}\n",
    "\n",
    "for col, prefix in zip(hashed_cols, prefixes):\n",
    "    # Get unique values from the column:\n",
    "    unique_values = [value for value in client_df[col].unique() if value!='MISSING']\n",
    "    unique_values.append('MISSING')\n",
    "\n",
    "    # Create new values\n",
    "    new_values = [f\"{prefix} {i}\" for i in range(1,len(unique_values))]\n",
    "    new_values.append(f'{prefix} Missing')\n",
    "\n",
    "    # Create a mapping dictionary\n",
    "    mapping_dicts[col] = dict(zip(unique_values, new_values))\n",
    "    print(f\"Mapping dictionary for '{col}':\\n\", mapping_dicts[col])\n",
    "    print('---------------------------------------------')\n",
    "\n",
    "mapping_dicts['churn'] = {0: 'No', 1: 'Yes'}\n",
    "print(f\"Mapping dictionary for 'churn':\\n\", mapping_dicts['churn'])\n",
    "print('---------------------------------------------')\n",
    "mapping_dicts['has_gas'] = {'f': 'No', 't': 'Yes'}\n",
    "print(f\"Mapping dictionary for 'has_gas':\\n\", mapping_dicts['has_gas'])\n",
    "print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New channel_sales values:\n",
      " ['Channel 1' 'Channel Missing' 'Channel 2' 'Channel 3' 'Channel 4'\n",
      " 'Channel 5' 'Channel 6' 'Channel 7']\n",
      "--------------------------------------------------\n",
      "New origin_up values:\n",
      " ['Campaign 1' 'Campaign 2' 'Campaign 3' 'Campaign Missing' 'Campaign 4'\n",
      " 'Campaign 5']\n",
      "--------------------------------------------------\n",
      "New churn values:\n",
      " ['Yes' 'No']\n",
      "--------------------------------------------------\n",
      "New has_gas values:\n",
      " ['Yes' 'No']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mapping_cols = hashed_cols\n",
    "mapping_cols.extend(['churn', 'has_gas'])\n",
    "\n",
    "# Apply the mapping to the column\n",
    "for col in mapping_cols:\n",
    "    client_df[col] = client_df[col].map(mapping_dicts[col])\n",
    "    print(f\"New {col} values:\\n\", client_df[col].unique())\n",
    "    print('--------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code performs essential quality checks to ensure data consistency and accuracy across both tables:\n",
    "\n",
    "1. Removing duplicate rows.\n",
    "2. Ensuring certain columns contain only positive values.\n",
    "\n",
    "Additional checks on `client_df` columns are:\n",
    "\n",
    "1. Ensuring ID values are unique\n",
    "2. Removing rows where `has_gas` is `'No'` but `cons_gas_12m` is greater than `0`.\n",
    "3. Confirming that `date_renewal` and `date_end` are always greater than or equal to `date_activ`. We assumed that `date_modif_prod` might be less than `date_activ`, in cases where the energy contract is modified only when you sign it, and this might happen before the activation date.\n",
    "4. Verifying that `margin_gross_pow_ele` is greater than or equal to `margin_net_pow_ele`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of rows in client_df: 14606\n",
      "Initial number of rows in price_df: 193002\n",
      "--------------------------------------------------------\n",
      "All IDs are unique.\n",
      "There are 53 rows with inconsistent 'has_gas' and 'cons_gas_12m' values.\n",
      "--------------------------------------------------------\n",
      "Final number of rows in client_df: 14553\n",
      "Final number of rows in price_df: 193002\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial number of rows in client_df: {client_df.shape[0]}\")\n",
    "print(f\"Initial number of rows in price_df: {price_df.shape[0]}\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "\n",
    "# Remove duplicate rows\n",
    "client_df = client_df.drop_duplicates()\n",
    "\n",
    "# Define function for checking non-positive values\n",
    "def remove_negative_values(df, cols, df_name, repo_path):\n",
    "    for col in cols:\n",
    "        negative_values_rows = df[df[col] < 0]\n",
    "        if not negative_values_rows.empty:\n",
    "            print(f\"Warning: '{col}' in {df_name} contains {negative_values_rows.shape[0]} non-positive values.\")\n",
    "            negative_values_rows.to_csv(f\"{repo_path}/data/{col}_negative_values_{df_name}.csv\", index=False)\n",
    "            df.drop(index=negative_values_rows.index, inplace=True)\n",
    "\n",
    "# Check if certain columns contain only positive values\n",
    "client_positive_cols = [\n",
    "    'cons_gas_12m', 'cons_12m', 'cons_gas_12m', 'cons_last_month', \n",
    "    'forecast_cons_12m', 'forecast_cons_year', 'forecast_discount_energy', \n",
    "    'forecast_meter_rent_12m', 'forecast_price_energy_off_peak',\n",
    "    'forecast_price_energy_peak', 'forecast_price_pow_off_peak',\n",
    "    'imp_cons', 'nb_prod_act', 'num_years_antig', 'pow_max'\n",
    "]\n",
    "price_positive_cols = [\n",
    "    'price_off_peak_var', 'price_peak_var', \n",
    "    'price_mid_peak_var', 'price_off_peak_fix', \n",
    "    'price_peak_fix', 'price_mid_peak_fix'\n",
    "]\n",
    "remove_negative_values(client_df, client_positive_cols, 'client_df', repo_path)\n",
    "remove_negative_values(price_df, price_positive_cols, 'price_df', repo_path)\n",
    "\n",
    "# Check if 'id' column is unique and report if any duplicate ids are found\n",
    "if client_df['id'].duplicated().any():\n",
    "    print(\"Warning: Duplicate IDs found.\")\n",
    "else:\n",
    "    print(\"All IDs are unique.\")\n",
    "\n",
    "# Remove rows where 'has_gas' is 'No' but 'cons_gas_12m' is not 0\n",
    "invalid_gas_rows = client_df[\n",
    "    (client_df['has_gas'] == 'No') & (client_df['cons_gas_12m'] != 0)\n",
    "]\n",
    "if not invalid_gas_rows.empty:\n",
    "    print(f\"There are {invalid_gas_rows.shape[0]} rows with inconsistent 'has_gas' and 'cons_gas_12m' values.\")\n",
    "    invalid_gas_rows.to_csv(f\"{repo_path}/data/gas_inconsistent_rows_client_df.csv\", index=False)\n",
    "    # client_df = client_df.drop(invalid_gas_rows.index)\n",
    "    client_df.drop(index=invalid_gas_rows.index, inplace=True)\n",
    "\n",
    "# Check that date_end and date_renewal are >= date_activ\n",
    "invalid_dates = client_df[\n",
    "    (client_df['date_end'] < client_df['date_activ']) |\n",
    "    (client_df['date_renewal'] < client_df['date_activ'])\n",
    "]\n",
    "if not invalid_dates.empty:\n",
    "    print(f\"There are {invalid_dates.shape[0]} rows with inconsistent dates.\")\n",
    "    invalid_dates.to_csv(f\"{repo_path}/data/invalid_dates_client_df.csv\", index=False)\n",
    "    client_df.drop(index=invalid_dates.index, inplace=True)\n",
    "    # client_df = client_df.drop(invalid_dates.index)\n",
    "\n",
    "# Verify that margin_gross_pow_ele is >= margin_net_pow_ele\n",
    "invalid_margin_rows = client_df[\n",
    "    client_df['margin_gross_pow_ele'] < client_df['margin_net_pow_ele']\n",
    "]\n",
    "if not invalid_margin_rows.empty:\n",
    "    print(f\"There are {invalid_margin_rows.shape[0]} rows with inconsistent margins.\")\n",
    "    invalid_margin_rows.to_csv(f\"{repo_path}/data/invalid_margin_rows_client_df.csv\", index=False)\n",
    "    client_df.drop(index=invalid_margin_rows.index, inplace=True)\n",
    "    # client_df = client_df.drop(invalid_margin_rows.index)\n",
    "\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(f\"Final number of rows in client_df: {client_df.shape[0]}\")\n",
    "print(f\"Final number of rows in price_df: {price_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>has_gas</th>\n",
       "      <th>cons_gas_12m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>d03b894570bbe809ab2ce610d52e4256</td>\n",
       "      <td>No</td>\n",
       "      <td>458306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>9f6aa89b4d15b6b60062a51a6b56698d</td>\n",
       "      <td>No</td>\n",
       "      <td>10542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>8c754ed545769094ac652456aa7d7110</td>\n",
       "      <td>No</td>\n",
       "      <td>298897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>201b65b25599462f94946cf16b386cb9</td>\n",
       "      <td>No</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>1c65d82e5ac151a43656de3fc026fc8e</td>\n",
       "      <td>No</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>645588ce9410be0d47f4c63783487493</td>\n",
       "      <td>No</td>\n",
       "      <td>3132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>aef79ff04e0c1e0af1f028428060a5c4</td>\n",
       "      <td>No</td>\n",
       "      <td>1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>2f52ef4f444bb56552c75ad3cb4385f6</td>\n",
       "      <td>No</td>\n",
       "      <td>21515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>d3cd0c17501d1d4c39dca734da32f4d5</td>\n",
       "      <td>No</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>c8e44781cf503ca69157b5c8474d5565</td>\n",
       "      <td>No</td>\n",
       "      <td>1270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id has_gas  cons_gas_12m\n",
       "211   d03b894570bbe809ab2ce610d52e4256      No        458306\n",
       "931   9f6aa89b4d15b6b60062a51a6b56698d      No         10542\n",
       "969   8c754ed545769094ac652456aa7d7110      No        298897\n",
       "993   201b65b25599462f94946cf16b386cb9      No           193\n",
       "1653  1c65d82e5ac151a43656de3fc026fc8e      No           191\n",
       "1672  645588ce9410be0d47f4c63783487493      No          3132\n",
       "1691  aef79ff04e0c1e0af1f028428060a5c4      No          1306\n",
       "1874  2f52ef4f444bb56552c75ad3cb4385f6      No         21515\n",
       "2075  d3cd0c17501d1d4c39dca734da32f4d5      No          1199\n",
       "2401  c8e44781cf503ca69157b5c8474d5565      No          1270"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_gas_rows[['id']+['has_gas', 'cons_gas_12m']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we perform a missing value analysis on `client_df` and `price_df`, displaying only columns with missing values. This helps identify areas requiring data imputation or cleaning.\n",
    "\n",
    "**Note**: A more detailed missing value assessment for `price_df` will be conducted in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'client_df': \n",
      "Series([], dtype: int64)\n",
      "Missing values in 'price_df': \n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in client_df\n",
    "missing_values_client = client_df.isnull().sum()\n",
    "\n",
    "# Display the columns with missing values\n",
    "print(\"Missing values in 'client_df': \")\n",
    "print(missing_values_client[missing_values_client > 0])\n",
    "\n",
    "# Check for missing values in price_df\n",
    "missing_values_price = price_df.isnull().sum()\n",
    "\n",
    "# Display the columns with missing values\n",
    "print(\"Missing values in 'price_df': \")\n",
    "print(missing_values_price[missing_values_price > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since no columns contain missing values, data imputation is not needed. \n",
    "\n",
    "We can now save the cleaned datasets as new CSV files for use in the `Churn Prediction - Part 2` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df.to_csv(f\"{repo_path}/data/client_data_cleaned.csv\", index=False)\n",
    "price_df.to_csv(f\"{repo_path}/data/price_data_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Workbench Python",
   "language": "python",
   "name": "workbench_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
