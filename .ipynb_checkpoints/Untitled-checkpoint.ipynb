{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf263ab-f7c3-4d7b-99a7-4a5b99e1e71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   feature_0  feature_1  feature_2  feature_3  feature_4\n",
       " 0   0.496714        NaN   0.357787  -0.828995  -1.594428\n",
       " 1  -0.138264  -0.420645   0.560785  -0.560181  -0.599375\n",
       " 2   0.647689        NaN        NaN   0.747294   0.005244\n",
       " 3   1.523030  -0.802277        NaN        NaN        NaN\n",
       " 4  -0.234153  -0.161286  -1.377669  -0.020902  -0.450065,\n",
       " array([0, 0, 1, 0, 0, 1, 0, 1, 1, 1]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create a fake dataset with missing values and numerical features\n",
    "n_samples = 100\n",
    "n_features = 5\n",
    "\n",
    "# Create numerical data with missing values\n",
    "X_fake = pd.DataFrame({\n",
    "    f\"feature_{i}\": np.random.randn(n_samples) for i in range(n_features)\n",
    "})\n",
    "# Introduce missing values in some columns\n",
    "missing_rate = 0.2\n",
    "for col in X_fake.columns:\n",
    "    X_fake.loc[X_fake.sample(frac=missing_rate).index, col] = np.nan\n",
    "\n",
    "# Create a binary target variable\n",
    "y_fake = np.random.choice([0, 1], size=n_samples)\n",
    "\n",
    "# Display the first few rows of the fake dataset\n",
    "X_fake.head(), y_fake[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ac3b4a2-c5cd-4813-89c7-4b4178651a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Custom Transformer for Missing Value Imputation\n",
    "class MissingValueImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, missing_numeric_cols):\n",
    "        self.missing_numeric_cols = missing_numeric_cols\n",
    "        self.imputation_models = {}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        for col in self.missing_numeric_cols:\n",
    "            if X[col].isnull().any():\n",
    "                # Prepare data for imputation\n",
    "                non_missing_data = X[X[col].notnull()]\n",
    "                train_features = non_missing_data.drop(columns=[col])\n",
    "                train_target = non_missing_data[col]\n",
    "                \n",
    "                # Train the imputation model\n",
    "                imputation_model = SASDecisionTreeRegressor()\n",
    "                nominal_features = train_features.select_dtypes(exclude='number').columns.tolist()\n",
    "                if len(nominal_features)>0:\n",
    "                    imputation_model.fit(train_features, train_target, nominals=nominal_features)\n",
    "                else:\n",
    "                    imputation_model.fit(train_features, train_target)\n",
    "                \n",
    "                # Store the model for this column\n",
    "                self.imputation_models[col] = imputation_model\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        for col, model in self.imputation_models.items():\n",
    "            # Separate rows with missing values\n",
    "            missing_data = X[X[col].isnull()]\n",
    "            if not missing_data.empty:\n",
    "                missing_features = missing_data.drop(columns=[col])\n",
    "                imputed_values = model.predict(missing_features)\n",
    "                \n",
    "                # Fill missing values\n",
    "                X.loc[X[col].isnull(), col] = imputed_values\n",
    "        return X\n",
    "\n",
    "# Custom Transformer for Scaling\n",
    "class DataScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, numeric_cols):\n",
    "        self.numeric_cols = numeric_cols\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X[self.numeric_cols])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.numeric_cols] = self.scaler.transform(X[self.numeric_cols])\n",
    "        return X\n",
    "\n",
    "# Pipeline Creation\n",
    "def create_pipeline(model, numeric_cols, nominals=None):\n",
    "    return Pipeline([\n",
    "        ('imputer', MissingValueImputer(numeric_cols=numeric_cols, nominals=nominals)),\n",
    "        ('scaler', DataScaler(numeric_cols=numeric_cols)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "# Example Usage\n",
    "# pipeline = create_pipeline(\n",
    "#     model=best_model,  # Replace with your trained model\n",
    "#     numeric_cols=numeric_columns_list, \n",
    "#     nominals=nominal_columns_list\n",
    "# )\n",
    "\n",
    "# # Fit the pipeline on the training data\n",
    "# pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on new data\n",
    "# predictions = pipeline.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e36d766-783e-4de8-b303-8196612d536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_cols = [col for col in X_fake.columns if X_fake[col].isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e467e74-8ad9-4b24-af1d-a48606e1fc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c96b1ce2-dac7-461d-92d1-00f9522c0461",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (354174851.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    missing = MissingValueImputer(numeric_cols=missing_cols, nominals=)\u001b[0m\n\u001b[0m                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "missing = MissingValueImputer(numeric_cols=missing_cols, nominals=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb14a2e-6c71-4db5-ba0d-383e1d17427c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Workbench Python",
   "language": "python",
   "name": "workbench_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
